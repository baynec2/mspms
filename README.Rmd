---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# msp-ms

<!-- badges: start -->
<!-- badges: end -->

The goal of mspms is provide a concise code-base for the normalization and data processing required to analyze data from the [Multiplex Substrate Profiling by Mass Spectrometry (MSP-MS) method](https://pubmed.ncbi.nlm.nih.gov/36948708/). 


Additionally, we provide a [graphical user interface powered by shiny apps](https://gonzalezlab.shinyapps.io/mspms_shiny/) that allows for a user to utilize the method without requiring any R coding knowledge. 



## Installation


You can install the released version of mspms from github

```{r,eval = FALSE}
devtools::install_github("baynec2/mspms")
```

## Workflow

So how does the msps data normalization process work?

1. Takes two input files from PEAKS and combines them
3. Normalizes values and then does a reverse log2 transformation
4. Looks for outliers across replicates. Removes them. 
5. Imputes data for missing values (likely to be very low intesity).
6. Figures out the locations of the detected clevages within the library of peptide sequences used. Is it cleaved at the N or C terminus, or both?
7. Calculates the fold change and the p/q value across experimental conditions using T-tests. 


### Combining Peaks file outputs

The files coming from peaks should have..... **Describe how to do this here**.



Importantly, this. data contains... what????


```{r}
library(dplyr)
library(mspms)

### Loading the files ###
lfq_filename = "legacy/protein-peptides-lfq.csv"
#file "protein-peptides.csv" exported from PEAKS identification
id_filename = "legacy/protein-peptides-id.csv"

# Prepare the data for normalyzer analysis
prepared_data = prepare_for_normalyzer(lfq_filename,id_filename)
```


### Loading design matrix

Before we normalyze data, we need to know what samples are in what groups. We can do that by defining a design matrix. 
```{r}
design_matrix = readr::read_csv("annotation.csv")

head(design_matrix)

```
### Normalyzing data

msp-ms uses the .... package to do normalization under the hood. 


Now we can normalyze the data.
```{r}
normalyzed_data = normalyze(prepared_data,design_matrix)
```

### Handling Outliers

Here we use a dixon test from the outliers package to detect outliers from each of our replicates. We need to know what samples are part of which groups, so we need to specify the design matrix here too. Make sure that the column header names are "sample" and "group" just like before.

```{r}
design_matrix = readr::read_csv("annotation.csv")
outliers = handle_outliers(normalyzed_data,design_matrix)
```

### Imputation of data 

We have a lot of missing, or 0 values. For these, we need to impute them so we can do downstream statistics
Data is imputated by ....

```{r}
imputed = impute(outliers)
```


### Joining with Library

Next we need to join everything with the sequences of the peptide library
```{r}
joined_with_library = join_with_library(imputed)
```



### Calcuating clevages
Next, we need to determine where the peptide sequences are cleaved. 

We check both the N and C terminus. 

Sequences are presented as the 4 amino acids on both sides of a cleavage. X indicates that there was nothing on that side in the library because it was cleaved close to the edge. 

```{r}
final_data = add_cleavages(joined_with_library)

head(final_data)
```


### Conducting stats

Right now this is left to the user to do on their own. Will update after talkng to Bri.

```{r}

#Figuring out where the samples start
start_of_samples = names(final_data)[which(names(final_data) == "z")+1]

# Combining with design matrix
long = final_data %>% 
 tidyr::pivot_longer(start_of_samples:length(.),names_to = "sample") %>% 
 inner_join(design_matrix,by = "sample")

# What is the control group called?
control_group = "DMSO_T0"

# calculating log2 FC
control_data = long %>% 
  filter(group == control_group) %>% 
  group_by(Peptide) %>% 
  summarise(control_mean = mean(value,na.rm = TRUE))

reference_group = "DMSO_T240"

reference_data = long %>% 
  filter(group == reference_group) %>% 
  group_by(Peptide) %>% 
  summarise(reference_mean = mean(value,na.rm = TRUE))

log2fc = inner_join(control_data,reference_data,by = "Peptide") %>% 
 dplyr::mutate(comparison = paste0(control_group,"_",reference_group),
         log2fc = log2(reference_mean/control_mean)) %>% 
  dplyr::select(Peptide,comparison,log2fc)



# Doing T tests

stat = long %>% 
  filter(group %in% c(control_group,reference_group)) %>%
  group_by(Peptide) %>%
  rstatix::t_test(value ~ group) %>%
  rstatix::adjust_pvalue(method = "fdr") %>% 
  mutate(comparison = paste0(group1,"_",group2)) 

combined = inner_join(log2fc,stat,by = c("Peptide","comparison"))



```




```{r}

# Lets do anova to see if there are any differences among groups
stat = long %>% 
  group_by(Peptide) %>% 
  rstatix::anova_test(formula = value ~ group) %>% 
  rstatix::adjust_pvalue(method = "fdr")

sig = stat %>% 
  as.data.frame() %>% 
  dplyr::filter(p.adj < 0.05) %>% 
  dplyr::pull(Peptide)


p1 = long %>%
  mutate(peptide %in% stat)
  ggplot(aes())

```


